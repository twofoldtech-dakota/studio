{
  "description": "STUDIO Orchestration Hook System - Wires orchestration to commands and agents",
  "version": "5.0.0",
  "hooks": {
    "PreToolUse": [
      {
        "matcher": "Task",
        "hooks": [
          {
            "type": "prompt",
            "prompt": "Before spawning a subagent, check if orchestration is active (.studio/orchestration/.current exists). If active and the subagent is planner or builder: 1) Run scripts/skills.sh detect \"$GOAL\" to find matching skills. 2) For each detected skill, run scripts/skills.sh inject <skill> to get injection content. 3) Prepend this skill context to the agent's prompt so it receives domain-specific guidance."
          }
        ]
      }
    ],
    "PreCommand": [
      {
        "matcher": "build",
        "hooks": [
          {
            "type": "prompt",
            "prompt": "PLAN-FIRST WORKFLOW ENFORCEMENT:\n\nThe /build command requires an EXISTING PLAN. It does NOT accept raw goal strings.\n\n1. CHECK the argument:\n   - If argument looks like a raw goal (quoted string describing work, e.g., 'Add user auth'):\n     STOP and tell the user:\n     \"The /build command requires an existing plan. Raw goals are not accepted.\n     \n     To build this feature:\n     1. First run: /studio \"<their goal>\"\n     2. Answer the planning questions\n     3. Then run: /build task_xxx\n     \n     This ensures requirements are gathered before coding begins.\"\n     DO NOT PROCEED with building.\n\n   - If argument is a task_id (task_YYYYMMDD_HHMMSS), feature ID (F#), epic ID (E#), or empty:\n     PROCEED with build - load the plan from .studio/tasks/\n\n2. IF proceeding with a valid task:\n   - Verify .studio/tasks/<task_id>/plan.json exists\n   - If plan doesn't exist, tell user to run /studio first\n   - Load the plan and proceed with execution\n\n3. VALIDATE the plan before building (BLOCKING GATE):\n   - Run: scripts/validate-plan.sh --task-id <task_id>\n   - Check exit code: 0 = pass, 1 = errors, 2 = warnings only\n   - IF exit code 1 (ERRORS):\n     * Show all errors in a red box using scripts/output.sh error_box\n     * DO NOT PROCEED - tell user:\n       \"Plan validation FAILED. Fix errors before build:\n       [list errors]\n       Edit .studio/tasks/<task_id>/plan.json or regenerate with /studio\"\n     * STOP - do not continue to build\n   - IF exit code 2 (WARNINGS only):\n     * Show warnings in yellow\n     * Ask: \"Plan has warnings. Continue anyway? (y/n)\"\n     * Only proceed if user confirms\n   - IF exit code 0: continue to build\n\n4. Initialize orchestration for tracking:\n   - Run: scripts/orchestrator.sh init \"executing task\" implicit\n   - Run: scripts/orchestrator.sh agent-start builder"
          },
          {
            "type": "prompt",
            "prompt": "KNOWLEDGE BASE INJECTION:\n\nBefore starting the build, inject Strict Constraints as a \"NEVER VIOLATE\" list:\n\n1. READ STUDIO_KNOWLEDGE_BASE.md\n2. EXTRACT the Strict Constraints section\n3. IF there are entries:\n   - Present them as: \"STRICT CONSTRAINTS (NEVER VIOLATE):\"\n   - List each SC-XXX entry with its \"What\" and \"Instead\" fields\n4. EXTRACT relevant Slop Ledger entries based on detected domains:\n   - Run: scripts/learnings.sh detect \"$GOAL\"\n   - For each detected domain, include matching slop entries\n5. Present slop entries as: \"AVOID THESE MISTAKES:\"\n   - List each SL-XXX entry with its \"Pattern\" and \"Fix\" fields\n\nThis ensures the build agent is aware of known constraints before writing code."
          },
          {
            "type": "prompt",
            "prompt": "QUALITY PRE-CHECK (OPTIONAL):\n\nBefore building, optionally run quality checks:\n\n1. RUN: scripts/quality-precheck.sh --json\n2. IF exit code 1 (errors): warn user but allow proceeding\n3. IF --skip-precheck flag passed: skip this step\n4. Show summary of issues found\n\nThis catches lint/type errors BEFORE the build."
          },
          {
            "type": "prompt",
            "prompt": "CONFIDENCE CHECK:\n\nBefore building, verify plan confidence:\n\n1. RUN: scripts/confidence-score.sh --task-id <task_id> --json\n2. CHECK the recommendation field:\n   - PROCEED_WITH_CONFIDENCE (>=80): Continue\n   - PROCEED_WITH_CAUTION (60-79): Warn user, allow proceed\n   - REVIEW_WARNINGS (40-59): Show warnings, ask to confirm\n   - DO_NOT_BUILD (<40): BLOCK - tell user to improve plan first\n3. IF blocked, show the warnings and suggest:\n   - Add more user confirmations (run questioning again)\n   - Add retry behavior to steps\n   - Define acceptance criteria\n\nThis prevents weak plans from wasting build cycles."
          }
        ]
      },
      {
        "matcher": "studio",
        "hooks": [
          {
            "type": "prompt",
            "prompt": "CONTEXT7 MCP INTEGRATION - FETCH LIBRARY DOCUMENTATION:\n\nDuring context gathering, use Context7 MCP to fetch relevant library documentation:\n\n1. DETECT libraries from the project:\n   - Read package.json dependencies and devDependencies\n   - Read requirements.txt or pyproject.toml if Python\n   - Read go.mod if Go, Cargo.toml if Rust\n\n2. IDENTIFY libraries relevant to the goal (max 3):\n   - Match goal keywords to library names\n   - Example: goal Add form validation + react-hook-form in deps = relevant\n\n3. FOR EACH relevant library:\n   a) Call Context7 MCP tool resolve-library-id:\n      - libraryName: package name (e.g., react-hook-form)\n      - query: the users goal\n   b) If found, call Context7 MCP tool query-docs:\n      - libraryId: resolved ID from step a\n      - query: specific question about the goal\n\n4. EMBED documentation in plan context:\n   - Add library_docs section to plan\n   - Include best practices and code patterns\n\n5. IF Context7 unavailable, continue without docs.\n\nThis ensures plans include up-to-date library guidance."
          },
          {
            "type": "prompt",
            "prompt": "BACKLOG & DECOMPOSITION CHECK:\n\nBEFORE starting the questioning protocol, determine the project state:\n\n1. CHECK if backlog exists: test -f .studio/backlog.json\n\n2. IF BACKLOG EXISTS (returning user):\n   - This is an EXISTING project with enterprise decomposition\n   - After questioning, add the new task to the EXISTING backlog\n   - Use: scripts/backlog.sh add-task <feature-id> \"<task-name>\" \"<description>\"\n   - If no matching feature exists, ask user which feature/epic to add to, or create new\n   - DO NOT create a new decomposition map\n   - Skip to the questioning protocol below\n\n3. IF NO BACKLOG (first-time user):\n   - Run: scripts/decomposition-check.sh json \"$GOAL\"\n   - IF should_trigger == true:\n     * Notify user: \"This appears to be a large-scale project (reason: [trigger_reason]).\"\n     * Ask: \"Would you like to:\n       1. Use enterprise decomposition (recommended for 10+ task projects)\n       2. Proceed with standard planning (single task)\n       \"\n     * WAIT FOR USER RESPONSE\n   - IF user chooses enterprise decomposition OR should_trigger == true and user confirms:\n     * Run: scripts/backlog.sh init\n     * Load: studio/prompts/enterprise-decomposition.md\n     * Follow the Decomposition Map output sequence\n     * Generate pillar analysis, hierarchy, SICVF validation, dependency graph\n     * WAIT FOR USER APPROVAL of decomposition map\n     * Tasks will be added to backlog, not .studio/tasks/\n   - IF should_trigger == false OR user chooses standard planning:\n     * Proceed with normal questioning protocol (creates standalone task in .studio/tasks/)"
          },
          {
            "type": "prompt",
            "prompt": "MANDATORY QUESTIONING PROTOCOL:\n\nThe /plan command MUST gather requirements through iterative questioning before creating a plan.\n\nYOU MUST FOLLOW THIS PROTOCOL:\n\n1. CONTEXT GATHERING (do silently):\n   - Load learnings from studio/learnings/*.md\n   - Scan codebase structure\n   - Detect relevant skills: scripts/skills.sh detect \"$GOAL\"\n\n2. MANDATORY QUESTIONING ROUNDS - YOU MUST ASK THESE QUESTIONS AND WAIT FOR ANSWERS:\n\n   ROUND 1 - Scope & Success (REQUIRED):\n   Ask the user:\n   - What functionality is IN scope for this task?\n   - What is explicitly OUT of scope?\n   - How will you know when this is complete?\n   \n   WAIT FOR USER RESPONSE before continuing.\n\n   ROUND 2 - Technical Constraints (REQUIRED):\n   Ask the user:\n   - Are there existing patterns I should follow?\n   - What dependencies or integrations are needed?\n   - Any technical constraints I should know about?\n   \n   WAIT FOR USER RESPONSE before continuing.\n\n   ROUND 3 - Edge Cases (REQUIRED):\n   Ask ADVERSARIAL questions specific to their goal:\n   - What if [likely error condition]?\n   - What happens when [external dependency] fails?\n   - Could this conflict with [existing feature]?\n   \n   WAIT FOR USER RESPONSE before continuing.\n\n3. READINESS CHECK (REQUIRED):\n   After Round 3, ask:\n   \"I have gathered requirements. Would you like to:\n   1. Continue with more questions\n   2. Create the plan now\"\n   \n   WAIT FOR USER RESPONSE.\n\n4. ONLY AFTER USER CONFIRMS proceed to plan creation.\n\nDO NOT skip questions. DO NOT create a plan without asking at least 3 rounds of questions."
          }
        ]
      }
    ],
    "SessionStart": [
      {
        "matcher": "startup",
        "hooks": [
          {
            "type": "command",
            "command": "mkdir -p .studio/tasks .studio/orchestration .studio/.cache/summaries 2>/dev/null || true"
          },
          {
            "type": "prompt",
            "prompt": "STUDIO INITIALIZATION:\n\n1. ENSURE directories exist:\n   - mkdir -p .studio/orchestration\n   - mkdir -p .studio/tasks\n   - mkdir -p .studio/.cache/summaries\n\n2. LOAD learnings from studio/learnings/*.md files.\n   Report: 'STUDIO ready. Loaded [N] learnings from [domains].'\n\n3. CHECK for tasks with IN_PROGRESS status in .studio/tasks/ and notify user if found.\n\n4. CHECK context budget status using scripts/context-manager.sh status.\n   If any pool is at WARNING (80%+) or CRITICAL (95%+) level, notify:\n   'Context pressure detected in [pool]. Consider running context optimization.'"
          },
          {
            "type": "prompt",
            "prompt": "ORCHESTRATION RESUME CHECK:\n\n1. Check if .studio/orchestration/.current exists\n2. If it does, read the session ID and load .studio/orchestration/<session_id>/state.json\n3. Check the 'status' field:\n   - If 'paused': Notify user 'Paused orchestration found: [session_id]. Goal: [goal]. Resume with /orchestrate resume or start fresh?'\n   - If 'recovering': Notify user 'Orchestration in recovery: [session_id]. Last failure: [error]. Resume recovery or abort?'\n   - If 'executing': Notify user 'Interrupted orchestration detected: [session_id]. Would you like to resume from the last checkpoint?'\n4. If user wants to resume, run: scripts/orchestrator.sh resume"
          },
          {
            "type": "prompt",
            "prompt": "KNOWLEDGE BASE LOADING:\n\n1. READ STUDIO_KNOWLEDGE_BASE.md if it exists\n2. COUNT entries in each section:\n   - Strict Constraints: [N]\n   - Slop Ledger: [N]\n   - Performance Delta: [N]\n   - Pending Queue: [N]\n3. REPORT: 'Knowledge base loaded: [total] entries ([constraints] constraints, [slop] slop, [perf] performance deltas)'\n4. IF Strict Constraints exist, summarize the top 3 most important rules\n5. CHECK sprint counter status:\n   - Read .studio/sprint-counter.json\n   - Report: 'Sprint [N]: [tasks]/5 tasks until evolution'\n   - If evolution is due (5+ tasks), notify: 'Sprint evolution due - consider running scripts/sprint-evolution.sh propose'"
          }
        ]
      }
    ],
    "SubagentStop": [
      {
        "matcher": "planner|builder|architect",
        "hooks": [
          {
            "type": "prompt",
            "prompt": "AGENT COMPLETION PROTOCOL:\n\n1. CHECK if orchestration is active (.studio/orchestration/.current exists)\n\n2. IF orchestration active:\n   a) Run: scripts/orchestrator.sh agent-complete [agent_name]\n   b) Run: scripts/orchestrator.sh checkpoint '[agent_name]_complete'\n   c) This auto-saves state for recovery\n\n3. IF this was the Planner:\n   - Prepare handoff context with task_id, plan_path, detected skills\n   - Run: scripts/orchestrator.sh handoff planner builder '{\"task_id\": \"...\", \"plan_path\": \"...\", \"skills\": [...]}'\n\n4. IF this was the Builder (and agent_name matches):\n   - Continue to learning capture phase"
          }
        ]
      },
      {
        "matcher": "builder",
        "hooks": [
          {
            "type": "agent",
            "prompt": "SELF-LEARNING PROTOCOL: Capture learnings from this build cycle.\n\nREAD studio/prompts/self-learning.md for the full protocol.\nREAD STUDIO_KNOWLEDGE_BASE.md for existing patterns to avoid duplicates.\n\n1. GENERATE task_id: task_YYYYMMDD_brief_description (e.g., task_20240215_auth_fix)\n\n2. DETECT domain automatically:\n   - Run: git diff --name-only HEAD~1 (or check changed files in this session)\n   - Map file patterns to domains:\n     - **/components/**, *.tsx, *.css → frontend\n     - **/api/**, **/services/** → backend\n     - **/*test*, **/__tests__/** → testing\n     - **/auth/**, **/security/** → security\n     - Performance improvements with metrics → performance\n     - Otherwise → global\n\n3. CLASSIFY the learning using scripts/signal-audit.sh:\n   - Run: scripts/signal-audit.sh classify \"<summary of what happened>\"\n   - Check output for: signal_type, destination, suggested_severity\n\n4. CHECK for duplicates:\n   - Run: scripts/learnings.sh check-duplicate \"<learning title>\" (if command exists)\n   - Or manually scan STUDIO_KNOWLEDGE_BASE.md for similar entries\n\n5. EXTRACT mandatory fields:\n   - task_id: [generated above]\n   - domain: [detected domain]\n   - impact_type: constraint | slop | performance | pattern\n   - severity: HIGH | MEDIUM | LOW\n   - measurable_outcome: [before/after metrics if applicable]\n\n6. SAVE to appropriate destination based on signal_type:\n   - performance → Add to Performance Delta section in STUDIO_KNOWLEDGE_BASE.md (MUST have numbers)\n   - error (1st occurrence) → Add to Pending Queue in STUDIO_KNOWLEDGE_BASE.md\n   - error (2+ occurrences) → Promote to Strict Constraints\n   - convention → Add to Slop Ledger in STUDIO_KNOWLEDGE_BASE.md\n   - pattern → Save to studio/learnings/{domain}.md\n\n7. INCREMENT sprint counter:\n   - Run: scripts/sprint-evolution.sh increment <task_id>\n   - If output is 'EVOLUTION_DUE', notify user to run evolution proposals\n\n8. CONFIRM with user:\n   - Show: task_id, domain, impact_type, severity, destination\n   - Ask for approval before saving\n\n9. UPDATE Definition of Done checklist:\n   - [ ] Learning extracted and classified\n   - [ ] Knowledge base checked for duplicates\n   - [ ] Sprint counter incremented\n\nReturn {\"ok\": true, \"task_id\": \"...\", \"learnings_saved_to\": \"...\", \"sprint_status\": \"...\"} when complete.",
            "timeout": 180
          }
        ]
      },
      {
        "matcher": "builder",
        "hooks": [
          {
            "type": "prompt",
            "prompt": "AUTO SPRINT EVOLUTION CHECK:\n\nAfter each build completes:\n\n1. RUN: scripts/sprint-evolution.sh status\n2. CHECK output for evolution_due field\n3. IF evolution_due == true:\n   - RUN: scripts/sprint-evolution.sh propose\n   - PRESENT proposals inline to user\n   - Ask: \"Sprint evolution proposals generated. Would you like to review and apply any?\"\n4. IF not due, silently continue\n\nThis triggers automatic improvement proposals every 5 completed tasks."
          }
        ]
      }
    ],
    "Stop": [
      {
        "matcher": "",
        "hooks": [
          {
            "type": "prompt",
            "prompt": "Check if there is an active build task with status BUILDING that has not passed quality gates. If found, warn the user: 'Build in progress without quality gate verification. Are you sure you want to stop?' and ask for confirmation before allowing stop."
          },
          {
            "type": "prompt",
            "prompt": "Check for active orchestration session in .studio/orchestration/.current. If found, save a checkpoint using scripts/orchestrator.sh checkpoint 'session_interrupted' before stopping. Report: 'Orchestration checkpoint saved. Resume with /orchestrate resume.'"
          }
        ]
      }
    ],
    "SubagentStart": [
      {
        "matcher": "planner|builder|architect",
        "hooks": [
          {
            "type": "prompt",
            "prompt": "AGENT STARTUP PROTOCOL:\n\n1. CHECK if orchestration is active (.studio/orchestration/.current exists)\n\n2. IF orchestration active:\n   a) Run: scripts/orchestrator.sh agent-start [agent_name]\n   b) Check for incoming handoff: scripts/orchestrator.sh get-handoff [agent_name]\n      - If handoff exists, include the context_passed data in agent context\n      - This contains task_id, plan_path, learnings, and other workflow context\n\n3. DETECT relevant skills for this agent's work:\n   a) Get the current goal from orchestration state or user input\n   b) Run: scripts/skills.sh detect \"$GOAL\"\n   c) For each detected skill (sorted by score):\n      - Run: scripts/skills.sh inject <skill_name>\n      - Include the injection content (questions, guidelines, checklist) in agent context\n\n4. SKILL INJECTION FORMAT:\n   If skills detected, prepend to agent context:\n   ---\n   ## Active Skills: [skill1, skill2]\n   \n   [Injection content from each skill]\n   ---\n\nThis ensures agents receive domain-specific guidance before execution."
          },
          {
            "type": "prompt",
            "prompt": "KNOWLEDGE BASE INJECTION FOR AGENTS:\n\n1. READ STUDIO_KNOWLEDGE_BASE.md\n\n2. EXTRACT and inject Strict Constraints:\n   - Format as: \"## STRICT CONSTRAINTS (NEVER VIOLATE)\"\n   - List each constraint with its \"What\" and \"Instead\" fields\n   - These are BLOCKING rules - agent must not proceed if it would violate\n\n3. DETECT domains relevant to the agent's goal:\n   - Run: scripts/learnings.sh detect \"$GOAL\"\n\n4. EXTRACT relevant Slop Ledger entries for detected domains:\n   - Format as: \"## AVOID THESE MISTAKES\"\n   - List each slop entry with its \"Pattern\" and \"Fix\" fields\n\n5. INJECT into agent context BEFORE the main task prompt:\n   ---\n   ## STRICT CONSTRAINTS (NEVER VIOLATE)\n   [constraints]\n   \n   ## AVOID THESE MISTAKES\n   [relevant slop entries]\n   ---\n\nThis ensures agents are aware of known pitfalls before execution."
          }
        ]
      }
    ],
    "ContextPressure": [
      {
        "matcher": "warning|critical",
        "hooks": [
          {
            "type": "prompt",
            "prompt": "Context pressure detected at {level} level. Run scripts/context-manager.sh scan to identify optimization opportunities. For learnings pool: consider summarizing entries older than 30 days. For plans pool: consider removing completed task plans. For context7 pool: clear cached docs for unused libraries."
          }
        ]
      }
    ]
  }
}
